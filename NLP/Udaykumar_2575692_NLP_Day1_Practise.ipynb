{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2b425c",
   "metadata": {},
   "source": [
    "# 1. What is the purpose of text preprocessing in NLP, and why is it essential before analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73183c29",
   "metadata": {},
   "source": [
    "Cleaning and modifying unstructured text data in order to make it ready for analysis is known as text preprocessing, and it is a crucial step in natural language processing (NLP). Tokenization, stemming, lemmatization, stop-word elimination, and part-of-speech labeling are all included.\n",
    "\n",
    "Tokenization: To make a text easier to analyze and comprehend, a text might be divided into discrete pieces, like words or phrases.\n",
    "\n",
    "Stemming: To extract the essential meaning and minimize dimensionality in text data, stemming is the process of taking words down to their most basic or root form.\n",
    "\n",
    "Lemmatization: In order to provide a uniform representation, lemmatization entails reducing words to their canonical or dictionary form while accounting for variances like verb conjugations and pluralization.\n",
    "\n",
    "Stop-word Elimination: This technique focuses on content-carrying words during analysis by eliminating frequent words (like \"and,\" \"the\") that don't significantly contribute to meaning.\n",
    "\n",
    "Part-of-Speech Tagging: This technique helps with syntactic analysis and comprehension of the text's structure by giving each word in a phrase a grammatical category (such as verb or noun)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdabb71c",
   "metadata": {},
   "source": [
    "# 2. Describe tokenization in NLP and explain its significance in text processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7fe97",
   "metadata": {},
   "source": [
    "The process of tokenization is breaking up text into smaller units like words, phrases, or characters. Because it produces structured input for analysis, this method is necessary for a variety of natural language processing applications. Tokenization is essential for tasks like information retrieval, sentiment analysis, and language translation because it improves language comprehension, feature extraction, and model comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eca0fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " Text preprocessing is an important step in Natural Language Processing (NLP) systems. It involves cleaning and preparing text data before applying machine learning algorithms. The purpose of text preprocessing is to remove noise from the data, such as stop words, punctuation, and terms that do not carry much weight in the context of the text. This cleaning process helps improve the performance of NLP systems by reducing variability and ensuring consistency in the data. Additionally, text preprocessing plays a crucial role in training word embeddings, which are essential for various NLP tasks.\n",
      "\n",
      "Aftr sentence Tokanization:\n",
      " ['Text preprocessing is an important step in Natural Language Processing (NLP) systems.', 'It involves cleaning and preparing text data before applying machine learning algorithms.', 'The purpose of text preprocessing is to remove noise from the data, such as stop words, punctuation, and terms that do not carry much weight in the context of the text.', 'This cleaning process helps improve the performance of NLP systems by reducing variability and ensuring consistency in the data.', 'Additionally, text preprocessing plays a crucial role in training word embeddings, which are essential for various NLP tasks.']\n",
      "\n",
      "no of sentnces:\n",
      " 5\n",
      "======================================================================\n",
      "\n",
      "Original text:\n",
      " Text preprocessing is an important step in Natural Language Processing (NLP) systems. It involves cleaning and preparing text data before applying machine learning algorithms. The purpose of text preprocessing is to remove noise from the data, such as stop words, punctuation, and terms that do not carry much weight in the context of the text. This cleaning process helps improve the performance of NLP systems by reducing variability and ensuring consistency in the data. Additionally, text preprocessing plays a crucial role in training word embeddings, which are essential for various NLP tasks.\n",
      "\n",
      "Aftr word Tokanization:\n",
      " ['Text', 'preprocessing', 'is', 'an', 'important', 'step', 'in', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'systems', '.', 'It', 'involves', 'cleaning', 'and', 'preparing', 'text', 'data', 'before', 'applying', 'machine', 'learning', 'algorithms', '.', 'The', 'purpose', 'of', 'text', 'preprocessing', 'is', 'to', 'remove', 'noise', 'from', 'the', 'data', ',', 'such', 'as', 'stop', 'words', ',', 'punctuation', ',', 'and', 'terms', 'that', 'do', 'not', 'carry', 'much', 'weight', 'in', 'the', 'context', 'of', 'the', 'text', '.', 'This', 'cleaning', 'process', 'helps', 'improve', 'the', 'performance', 'of', 'NLP', 'systems', 'by', 'reducing', 'variability', 'and', 'ensuring', 'consistency', 'in', 'the', 'data', '.', 'Additionally', ',', 'text', 'preprocessing', 'plays', 'a', 'crucial', 'role', 'in', 'training', 'word', 'embeddings', ',', 'which', 'are', 'essential', 'for', 'various', 'NLP', 'tasks', '.']\n",
      "\n",
      "no of words:\n",
      " 104\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text=\"\"\"Text preprocessing is an important step in Natural Language Processing (NLP) systems. It involves cleaning and preparing text data before applying machine learning algorithms. The purpose of text preprocessing is to remove noise from the data, such as stop words, punctuation, and terms that do not carry much weight in the context of the text. This cleaning process helps improve the performance of NLP systems by reducing variability and ensuring consistency in the data. Additionally, text preprocessing plays a crucial role in training word embeddings, which are essential for various NLP tasks.\"\"\"\n",
    "print('Original text:\\n',text)\n",
    "print()\n",
    "tokenised_sent=sent_tokenize(text)\n",
    "print('Aftr sentence Tokanization:\\n',tokenised_sent)\n",
    "print()\n",
    "print('no of sentnces:\\n',len(tokenised_sent))\n",
    "print('='*70)\n",
    "print()\n",
    "\n",
    "print('Original text:\\n',text)\n",
    "print()\n",
    "tokenised_word=word_tokenize(text)\n",
    "print('Aftr word Tokanization:\\n',tokenised_word)\n",
    "print()\n",
    "print('no of words:\\n',len(tokenised_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038c03f",
   "metadata": {},
   "source": [
    "# 3. What are the differences between stemming and lemmatization in NLP? When would you choose one over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425b87a7",
   "metadata": {},
   "source": [
    "Reducing words to their root form without taking linguistic context into account is known as stemming, and it frequently leads to less accurate but faster processing. Lemmatization takes into account the context and meaning of the word, yielding a more accurate but computationally demanding outcome. Select lemmatization when accuracy in linguistic analysis or language comprehension is critical; select stemming when information retrieval or search engines need to be efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea15c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Uday\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33f4c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Tokenized words - without stemming:\n",
      "\n",
      "\t ['Text', 'preprocessing', 'is', 'an', 'important', 'step', 'in', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'systems', '.', 'It', 'involves', 'cleaning', 'and', 'preparing', 'text', 'data', 'before', 'applying', 'machine', 'learning', 'algorithms', '.', 'The', 'purpose', 'of', 'text', 'preprocessing', 'is', 'to', 'remove', 'noise', 'from', 'the', 'data', ',', 'such', 'as', 'stop', 'words', ',', 'punctuation', ',', 'and', 'terms', 'that', 'do', 'not', 'carry', 'much', 'weight', 'in', 'the', 'context', 'of', 'the', 'text', '.', 'This', 'cleaning', 'process', 'helps', 'improve', 'the', 'performance', 'of', 'NLP', 'systems', 'by', 'reducing', 'variability', 'and', 'ensuring', 'consistency', 'in', 'the', 'data', '.', 'Additionally', ',', 'text', 'preprocessing', 'plays', 'a', 'crucial', 'role', 'in', 'training', 'word', 'embeddings', ',', 'which', 'are', 'essential', 'for', 'various', 'NLP', 'tasks', '.']\n",
      "======================================================================\n",
      "\n",
      "Tokenized words - afer stemming are:\n",
      "\t ['text', 'preprocess', 'is', 'an', 'import', 'step', 'in', 'natur', 'languag', 'process', '(', 'nlp', ')', 'system', '.', 'it', 'involv', 'clean', 'and', 'prepar', 'text', 'data', 'befor', 'appli', 'machin', 'learn', 'algorithm', '.', 'the', 'purpos', 'of', 'text', 'preprocess', 'is', 'to', 'remov', 'nois', 'from', 'the', 'data', ',', 'such', 'as', 'stop', 'word', ',', 'punctuat', ',', 'and', 'term', 'that', 'do', 'not', 'carri', 'much', 'weight', 'in', 'the', 'context', 'of', 'the', 'text', '.', 'thi', 'clean', 'process', 'help', 'improv', 'the', 'perform', 'of', 'nlp', 'system', 'by', 'reduc', 'variabl', 'and', 'ensur', 'consist', 'in', 'the', 'data', '.', 'addit', ',', 'text', 'preprocess', 'play', 'a', 'crucial', 'role', 'in', 'train', 'word', 'embed', ',', 'which', 'are', 'essenti', 'for', 'variou', 'nlp', 'task', '.']\n",
      "======================================================================\n",
      "lemmarized words:\n",
      " ['Text', 'preprocessing', 'be', 'an', 'important', 'step', 'in', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'systems', '.', 'It', 'involve', 'clean', 'and', 'prepare', 'text', 'data', 'before', 'apply', 'machine', 'learn', 'algorithms', '.', 'The', 'purpose', 'of', 'text', 'preprocessing', 'be', 'to', 'remove', 'noise', 'from', 'the', 'data', ',', 'such', 'as', 'stop', 'word', ',', 'punctuation', ',', 'and', 'term', 'that', 'do', 'not', 'carry', 'much', 'weight', 'in', 'the', 'context', 'of', 'the', 'text', '.', 'This', 'clean', 'process', 'help', 'improve', 'the', 'performance', 'of', 'NLP', 'systems', 'by', 'reduce', 'variability', 'and', 'ensure', 'consistency', 'in', 'the', 'data', '.', 'Additionally', ',', 'text', 'preprocessing', 'play', 'a', 'crucial', 'role', 'in', 'train', 'word', 'embeddings', ',', 'which', 'be', 'essential', 'for', 'various', 'NLP', 'task', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps=PorterStemmer()\n",
    "\n",
    "stemmed_words=[]\n",
    "\n",
    "for w in tokenised_word:\n",
    "    stemmed_words.append(ps.stem(w))\n",
    "    \n",
    "\n",
    "print('='*70)\n",
    "print('Tokenized words - without stemming:\\n\\n\\t',tokenised_word)\n",
    "print('='*70)\n",
    "print('\\nTokenized words - afer stemming are:\\n\\t',stemmed_words)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "\n",
    "lemma_words=[lemma.lemmatize(word,pos='v') for word in tokenised_word ]\n",
    "\n",
    "print('='*70)\n",
    "print('lemmarized words:\\n',lemma_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5858ad35",
   "metadata": {},
   "source": [
    "# 4. Explain the concept of stop words and their role in text preprocessing. How do they impact NLP tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf24dab",
   "metadata": {},
   "source": [
    "In text preparation, stop words—common words with minimal significance, like \"and\" or \"the\"—are frequently eliminated. By decreasing the number of dimensions in the data and increasing the relevance of informative terms, their removal lowers noise, concentrates analysis on words that convey meaning, and increases computational efficiency in natural language processing (NLP) applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55764da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of words:\t 104\n",
      "======================================================================\n",
      "Tokenized words - with stop words:\n",
      "\n",
      "\t ['Text', 'preprocessing', 'is', 'an', 'important', 'step', 'in', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'systems', '.', 'It', 'involves', 'cleaning', 'and', 'preparing', 'text', 'data', 'before', 'applying', 'machine', 'learning', 'algorithms', '.', 'The', 'purpose', 'of', 'text', 'preprocessing', 'is', 'to', 'remove', 'noise', 'from', 'the', 'data', ',', 'such', 'as', 'stop', 'words', ',', 'punctuation', ',', 'and', 'terms', 'that', 'do', 'not', 'carry', 'much', 'weight', 'in', 'the', 'context', 'of', 'the', 'text', '.', 'This', 'cleaning', 'process', 'helps', 'improve', 'the', 'performance', 'of', 'NLP', 'systems', 'by', 'reducing', 'variability', 'and', 'ensuring', 'consistency', 'in', 'the', 'data', '.', 'Additionally', ',', 'text', 'preprocessing', 'plays', 'a', 'crucial', 'role', 'in', 'training', 'word', 'embeddings', ',', 'which', 'are', 'essential', 'for', 'various', 'NLP', 'tasks', '.']\n",
      "======================================================================\n",
      "Length after the remoal of stopwords:\t 73\n",
      "======================================================================\n",
      "\n",
      "Tokenized words - afer removing the stopwords are:\n",
      "\t ['Text', 'preprocessing', 'important', 'step', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'systems', '.', 'It', 'involves', 'cleaning', 'preparing', 'text', 'data', 'applying', 'machine', 'learning', 'algorithms', '.', 'The', 'purpose', 'text', 'preprocessing', 'remove', 'noise', 'data', ',', 'stop', 'words', ',', 'punctuation', ',', 'terms', 'carry', 'much', 'weight', 'context', 'text', '.', 'This', 'cleaning', 'process', 'helps', 'improve', 'performance', 'NLP', 'systems', 'reducing', 'variability', 'ensuring', 'consistency', 'data', '.', 'Additionally', ',', 'text', 'preprocessing', 'plays', 'crucial', 'role', 'training', 'word', 'embeddings', ',', 'essential', 'various', 'NLP', 'tasks', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Uday\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "filtered_tokens=[]\n",
    "for w in tokenised_word:\n",
    "    if w not in stop_words:\n",
    "        filtered_tokens.append(w)\n",
    "print('Length of words:\\t',len(tokenised_word))\n",
    "print('='*70)\n",
    "print('Tokenized words - with stop words:\\n\\n\\t',tokenised_word)\n",
    "print('='*70)\n",
    "print('Length after the remoal of stopwords:\\t',len(filtered_tokens))\n",
    "print('='*70)\n",
    "print('\\nTokenized words - afer removing the stopwords are:\\n\\t',filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa5f5a",
   "metadata": {},
   "source": [
    "# 5. How does the process of removing punctuation contribute to text preprocessing in NLP? What are its benefits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485a627",
   "metadata": {},
   "source": [
    "When punctuation is removed during text preparation, non-semantic symbols are removed from the data, making the text cleaner and more focused for analysis. This reduces the amount of extraneous noise that affects the interpretation of textual content, improving the accuracy of NLP tasks like sentiment analysis and language modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d226dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " Text preprocessing is an important step in Natural Language Processing (NLP) systems. It involves cleaning and preparing text data before applying machine learning algorithms. The purpose of text preprocessing is to remove noise from the data, such as stop words, punctuation, and terms that do not carry much weight in the context of the text. This cleaning process helps improve the performance of NLP systems by reducing variability and ensuring consistency in the data. Additionally, text preprocessing plays a crucial role in training word embeddings, which are essential for various NLP tasks.\n",
      "======================================================================\n",
      "after removing puntuations:\n",
      "\n",
      "['Text', 'preprocessing', 'is', 'an', 'important', 'step', 'in', 'Natural', 'Language', 'Processing', 'NLP', 'systems', 'It', 'involves', 'cleaning', 'and', 'preparing', 'text', 'data', 'before', 'applying', 'machine', 'learning', 'algorithms', 'The', 'purpose', 'of', 'text', 'preprocessing', 'is', 'to', 'remove', 'noise', 'from', 'the', 'data', 'such', 'as', 'stop', 'words', 'punctuation', 'and', 'terms', 'that', 'do', 'not', 'carry', 'much', 'weight', 'in', 'the', 'context', 'of', 'the', 'text', 'This', 'cleaning', 'process', 'helps', 'improve', 'the', 'performance', 'of', 'NLP', 'systems', 'by', 'reducing', 'variability', 'and', 'ensuring', 'consistency', 'in', 'the', 'data', 'Additionally', 'text', 'preprocessing', 'plays', 'a', 'crucial', 'role', 'in', 'training', 'word', 'embeddings', 'which', 'are', 'essential', 'for', 'various', 'NLP', 'tasks']\n"
     ]
    }
   ],
   "source": [
    "words=[word for word in tokenised_word if word.isalpha()]\n",
    "\n",
    "print('Original text:\\n',text)\n",
    "print('='*70)\n",
    "\n",
    "print('after removing puntuations:\\n')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51b35f",
   "metadata": {},
   "source": [
    "# 6. Discuss the importance of lowercase conversion in text preprocessing. Why is it a common step in NLP tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95861420",
   "metadata": {},
   "source": [
    "Lowercase conversion is essential in text preprocessing to ensure uniformity in word representation, preventing the model from treating words in different cases as distinct entities. It enhances consistency and improves the efficiency of NLP tasks by reducing the complexity associated with case variations. Additionally, it aids in word matching and retrieval, promoting accurate linguistic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2da2008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " Text preprocessing is an important step in Natural Language Processing (NLP) systems. It involves cleaning and preparing text data before applying machine learning algorithms. The purpose of text preprocessing is to remove noise from the data, such as stop words, punctuation, and terms that do not carry much weight in the context of the text. This cleaning process helps improve the performance of NLP systems by reducing variability and ensuring consistency in the data. Additionally, text preprocessing plays a crucial role in training word embeddings, which are essential for various NLP tasks.\n",
      "======================================================================\n",
      "after lowering the case:\n",
      "\n",
      "['text', 'preprocessing', 'is', 'an', 'important', 'step', 'in', 'natural', 'language', 'processing', '(', 'nlp', ')', 'systems', '.', 'it', 'involves', 'cleaning', 'and', 'preparing', 'text', 'data', 'before', 'applying', 'machine', 'learning', 'algorithms', '.', 'the', 'purpose', 'of', 'text', 'preprocessing', 'is', 'to', 'remove', 'noise', 'from', 'the', 'data', ',', 'such', 'as', 'stop', 'words', ',', 'punctuation', ',', 'and', 'terms', 'that', 'do', 'not', 'carry', 'much', 'weight', 'in', 'the', 'context', 'of', 'the', 'text', '.', 'this', 'cleaning', 'process', 'helps', 'improve', 'the', 'performance', 'of', 'nlp', 'systems', 'by', 'reducing', 'variability', 'and', 'ensuring', 'consistency', 'in', 'the', 'data', '.', 'additionally', ',', 'text', 'preprocessing', 'plays', 'a', 'crucial', 'role', 'in', 'training', 'word', 'embeddings', ',', 'which', 'are', 'essential', 'for', 'various', 'nlp', 'tasks', '.']\n"
     ]
    }
   ],
   "source": [
    "lower_words=[word.lower() for word in tokenised_word]\n",
    "print('Original text:\\n',text)\n",
    "print('='*70)\n",
    "\n",
    "print('after lowering the case:\\n')\n",
    "print(lower_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05c94f",
   "metadata": {},
   "source": [
    "# 7. Explain the term \"vectorization\" concerning text data. How does techniques like CountVectorizer contribute to text preprocessing in NLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c8767",
   "metadata": {},
   "source": [
    "Text input is transformed into numerical vectors for machine learning models in NLP, a process known as vectorization. Text is converted into a matrix of word frequencies using methods such as CountVectorizer, which records the frequency of occurrence of each phrase. By producing a numerical representation that algorithms can employ for analysis and modeling, this aids in the preparation of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1982646d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      " ['additionally' 'algorithms' 'an' 'and' 'applying' 'are' 'as' 'before'\n",
      " 'by' 'carry' 'cleaning' 'consistency' 'context' 'crucial' 'data' 'do'\n",
      " 'embeddings' 'ensuring' 'essential' 'for' 'from' 'helps' 'important'\n",
      " 'improve' 'in' 'involves' 'is' 'it' 'language' 'learning' 'machine'\n",
      " 'much' 'natural' 'nlp' 'noise' 'not' 'of' 'performance' 'plays'\n",
      " 'preparing' 'preprocessing' 'process' 'processing' 'punctuation'\n",
      " 'purpose' 'reducing' 'remove' 'role' 'step' 'stop' 'such' 'systems'\n",
      " 'tasks' 'terms' 'text' 'that' 'the' 'this' 'to' 'training' 'variability'\n",
      " 'various' 'weight' 'which' 'word' 'words']\n",
      "**********************************************************************\n",
      "Token counts matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector=CountVectorizer()\n",
    "\n",
    "x=vector.fit_transform(tokenised_word)\n",
    "\n",
    "feature_names=vector.get_feature_names_out()\n",
    "\n",
    "print('Feature names:\\n',feature_names)\n",
    "print('*'*70)\n",
    "print('Token counts matrix:')\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c5d5e",
   "metadata": {},
   "source": [
    "# 8. Describe the concept of normalization in NLP. Provide examples of normalization techniques used in text preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd644df",
   "metadata": {},
   "source": [
    "The process of converting text data into a standardized and consistent format is known as normalization in natural language processing. In text preparation, some examples of normalizing approaches are as follows:\n",
    "\n",
    "Lowercasing: To guarantee consistency in word representation, every text should be converted to lowercase (e.g., \"Hello\" becomes \"hello\").\n",
    "\n",
    "Eliminating Accents and Diacritics: Removing accents from characters to make writing more standardized, like as changing \"résumé\" to \"resume.\"\n",
    "\n",
    "Handling Contractions: Extending contractions to represent words in their complete form (e.g., \"can't\" to \"cannot\") is known as handling contractions.\n",
    "\n",
    "Numeric and Date Normalization:The process of presenting various numerical or date formats consistently (e.g., \"10.5\" to \"10 point 5\" or \"2023-11-24\" to \"November 24, 2023\") is known as numeric and date normalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
